{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d94db4",
   "metadata": {},
   "source": [
    "$$\\text{Trabajo Final de Comunicaciones Digitales - Parte N° 1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8031bcfe",
   "metadata": {},
   "source": [
    "$\\text{Diseño del Codificador - Decodificador }$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a4e4c",
   "metadata": {},
   "source": [
    "# Marco Teórico\n",
    "\n",
    "## Codificador\n",
    "\n",
    "El **codificador** es el dispositivo que toma el mensaje y produce la palabra código. El mensaje consiste en una secuencia de bits de información que debe ser transformada para su transmisión eficiente.\n",
    "\n",
    "Si queremos comunicar una secuencia de $k$ bits, existen $2^k$ secuencias distintas y cada una debería ser mapeada a una secuencia de símbolos distinta. Esta relación se expresa matemáticamente como:\n",
    "\n",
    "$$2^k \\leq m^n$$\n",
    "\n",
    "donde $m$ es el tamaño del alfabeto de símbolos y $n$ es la longitud de la secuencia de símbolos.\n",
    "\n",
    "### Codificación Binaria Directa\n",
    "\n",
    "La base matemática para lo que llamamos **codificación binaria directa** consiste en agrupar $k$ bits y interpretarlos como un entero entre $0$ y $2^{k}-1$, el cual se mapea a un símbolo dentro de un alfabeto de tamaño $m = 2^k$.\n",
    "\n",
    "La fórmula que describe esta transformación es:\n",
    "\n",
    "$$\\text{Símbolo} = \\sum_{i=0}^{SF-1} b_i \\cdot 2^i$$\n",
    "\n",
    "donde:\n",
    "- $b_i$ es el $i$-ésimo bit del grupo\n",
    "- $SF$ es el Spreading Factor (Factor de Expansión)\n",
    "\n",
    "## Decodificador\n",
    "\n",
    "El **decodificador** es el dispositivo responsable de inferir el mensaje original a partir de la señal recibida. En el contexto del canal AWGN (Ruido Blanco Gaussiano Aditivo), el decodificador implementa una estrategia de **Máxima Verosimilitud** (Maximum Likelihood).\n",
    "\n",
    "### Decodificador de Máxima Verosimilitud\n",
    "\n",
    "Para un decodificador ML en el canal AWGN en tiempo discreto, se elige una de las secuencias de salida $\\mathbf{x}$ que maximiza la función de verosimilitud. La métrica de decisión se expresa como:\n",
    "\n",
    "$$\\langle \\mathbf{c}, \\mathbf{y} \\rangle - \\frac{|\\mathbf{c}|^2}{2}$$\n",
    "\n",
    "donde:\n",
    "- $\\mathbf{c}$ es la palabra código candidata\n",
    "- $\\mathbf{y}$ es la señal recibida\n",
    "- $\\langle \\mathbf{c}, \\mathbf{y} \\rangle$ es el producto interno entre ambos vectores\n",
    "- $|\\mathbf{c}|^2$ es la energía de la palabra código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c166d6a5",
   "metadata": {},
   "source": [
    "$\\text{Desarrollo}$\n",
    "\n",
    "$$\\text{Modulacion de chirp por desplazamiento de frecuencia}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fad5af",
   "metadata": {},
   "source": [
    "En el paper, el proceso de codificación en la modulación por desplazamiento de frecuencia mediante chirps se describe matemáticamente de manera precisa y puede descomponerse en tres etapas fundamentales:\n",
    "\n",
    "## Etapa 1: Mapeo de bits a símbolo decimal\n",
    "\n",
    "El proceso comienza con un vector $w(nT_s)$ compuesto por una cantidad determinada de bits. Esta cantidad se denomina **Spreading Factor** (SF). El Spreading Factor es el número de bits por símbolo y se calcula como:\n",
    "\n",
    "$$SF = \\log_2(M)$$\n",
    "\n",
    "donde $M$ es la cardinalidad de la modulación (la cantidad de símbolos distintos). Por ejemplo, si $SF = 5$, hay $2^5 = 32$ símbolos posibles.\n",
    "\n",
    "Una vez obtenido el vector $w(nT_s)$, se utiliza la fórmula planteada en el paper para sumar los valores ponderados de los bits del vector $w(nT_s)$ y así generar el valor decimal entero $s(nT_s)$. Este número se utiliza para decidir con qué frecuencia inicial el chirp inicia la transmisión.\n",
    "\n",
    "### Parámetros de transmisión\n",
    "\n",
    "Supongamos que el ancho de banda del canal que usamos para la transmisión es $B$ y que transmitimos una muestra cada $T$, con:\n",
    "\n",
    "$$T = \\frac{1}{B}$$\n",
    "\n",
    "Un símbolo $s(nT_s)$ es enviado a la entrada del modulador cada:\n",
    "\n",
    "$$T_s = 2^{SF} \\cdot T$$\n",
    "\n",
    "El símbolo $s(nT_s)$ es un número real que se forma usando un vector $w(nT_s)$ de dígitos binarios SF, con SF como un parámetro entero llamado **Factor de Expansión**, el cual normalmente toma valores en $\\{7, 8, 9, 10, 11, 12\\}$.\n",
    "\n",
    "El SF (Spreading Factor) es el número de bits que se agrupan en cada símbolo. Cada número representa un entero entre $0$ y $2^{SF} - 1$ y representa cuánto se \"esparce\" la señal en el tiempo, determinando la cantidad de símbolos que se pueden transmitir.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eaf08c",
   "metadata": {},
   "source": [
    "## Ecuación 1: Codificación de bits a símbolo\n",
    "\n",
    "El proceso de codificación transforma una secuencia de bits en símbolos que pueden ser transmitidos a través del canal. \n",
    "\n",
    "La codificación binaria directa agrupa $k$ bits consecutivos y los interpreta como un número entero entre $0$ y $2^k - 1$. Este número entero se mapea directamente a un símbolo dentro de un alfabeto de tamaño $m = 2^k$. \n",
    "\n",
    "La fórmula matemática que describe esta transformación es:\n",
    "\n",
    "$$s(nT_s) = \\sum_{h=0}^{SF-1} w_h(nT_s) \\cdot 2^h$$\n",
    "\n",
    "donde:\n",
    "- $s(nT_s) \\in {0,...,2^SF - 1}$ es el simbolo codificado \n",
    "- $w_h(nT_s) \\in {0,1}$ son los bits del bloque actual, ordenados desde el menos significativo (LSB).\n",
    "- $SF$ es el Spreading Factor (Factor de Expansión), que define la cantidad de bits por símbolo.\n",
    "- $h$ es el índice del bit dentro del bloque\n",
    "\n",
    "Entonces: \n",
    "    Esta operación convierte secuenci sbinarias en números enteros para su modulacíon, permitiendo la reperesentacíon \n",
    "    eficiente de la informacíon.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869cb87f",
   "metadata": {},
   "source": [
    "## Ecuación 2 y 3: Modulación Chirp \n",
    "\n",
    "**Ecuación 2 (forma general):**\n",
    "\n",
    "$$c(nT_s + kT) = \\frac{1}{\\sqrt{2^{SF}}} \\cdot e^{j2\\pi[(s(nT_s)+k) \\bmod 2^{SF}]\\frac{kT}{B}} \\quad (2)$$\n",
    "\n",
    "donde:\n",
    "- $c(nT_s + kT)$ es la señal chirp modulada en el tiempo $nT_s + kT$\n",
    "- $\\frac{1}{\\sqrt{2^{SF}}}$ es el factor de normalización de energía (asegura energía unitaria para cada símbolo)\n",
    "- $s(nT_s)$ es el símbolo codificado (de la Ecuación 1)\n",
    "- $k$ es el índice de muestra dentro del símbolo ($k = 0, 1, ..., 2^{SF}-1$)\n",
    "- $T$ es el período de muestreo\n",
    "- $B$ es el ancho de banda del canal\n",
    "- $\\bmod 2^{SF}$ indica la operación módulo $2^{SF}$\n",
    "\n",
    "### Características principales:\n",
    "\n",
    "1. **Chirp complejo**: La señal tiene frecuencia linealmente creciente dentro de cada símbolo\n",
    "2. **Frecuencia instantánea**: Depende de $(s(nT_s)+k) \\bmod 2^{SF}$, que representa un corrimiento de frecuencia específico para cada símbolo\n",
    "3. **Ortogonalidad**: Los diferentes símbolos generan chirps ortogonales entre sí, facilitando la decodificación\n",
    "4. **Normalización**: El factor $\\frac{1}{\\sqrt{2^{SF}}}$ mantiene la energía constante por símbolo\n",
    "\n",
    "\n",
    "  \n",
    "**Ecuación 3 (forma simplifca:**)\n",
    "\n",
    "\n",
    "Dado que $T = \\frac{1}{B}$, se reemplaza por $T \\cdot B = 1$, simplificando la ecuación:\n",
    "\n",
    "$$c(nT_s + kT) = \\frac{1}{\\sqrt{2^{SF}}} \\cdot e^{j2\\pi \\cdot \\frac{[(s(nT_s)+k) \\bmod 2^{SF}] \\cdot k}{2^{SF}}} \\quad (3)$$\n",
    "\n",
    "**Pasos** \n",
    "\n",
    "1. Definiciíon del tiempo discreto:  \n",
    "\n",
    "Teniendo en cuento lo definido más arriba: \n",
    " \n",
    "$$t = nT_s + kT = n \\cdot 2^ SF \\cdot T + kT$$\n",
    "\n",
    "2. Codificar la frecuencia en el chirp: \n",
    "\n",
    "La modulacíon LoRa usa un chirp de frecuencia creciente, donde la frecuencia instantánea varía linealmente con k, y \n",
    "se desplaza según el valor del símbolo $$s(nT_s)$$ \n",
    "$$\\frac{[(s+k) \\bmod 2^{SF}] \\cdot k}{2^{SF}}$$\n",
    "\n",
    "\n",
    "3. Fase acumulada y señal compleja \n",
    "\n",
    "$$e^{j2\\pi \\cdot \\frac{[(s+k) \\bmod 2^{SF}] \\cdot k}{2^{SF}}}$$\n",
    "\n",
    "Representa una señal compleja cuya fase cambia con el tiempo (índice k).Esa fase varía en funcíon del símbolo transmitido s y de la muestra actual k. \n",
    "Como resultado, se genera una onda chirp (señal cuya frecuencia aumenta linealmente con k ). Esto se logra porque la fase del exponente crece de forma cuadrática con k, algo característico de un chirp lineal. \n",
    "El desplazamiento s hace que cada símbolo comience su chirp en una frecuencia distinta, lo que permite codificar la información.\n",
    "\n",
    "4. Normalizacíon de energía \n",
    "\n",
    "El factor $\\frac{1}{\\sqrt{2^{SF}}}$ normaliza la señal para que tenga energía unitaria. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e127e",
   "metadata": {},
   "source": [
    "$\\text{Implementación en python}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652cd32",
   "metadata": {},
   "source": [
    "<text>La función bits_to_symbols: Agrupa un arreglo plano de bits en bloques de longitud igual al Spreading Factor (SF) y \n",
    "\n",
    "convierte cada bloque en un número decimal. Este paso simula lo que en el paper se describe como la generación del símbolo\n",
    " \n",
    "𝑠(𝑛𝑇𝑠) a partir del vector de bits 𝑤(𝑛𝑇𝑠)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43616cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def bits_to_symbols(bit_array, SF):\n",
    "    \"\"\"Agrupa los bits en bloques de SF y los convierte en símbolos enteros.\"\"\"\n",
    "    bit_array = np.array(bit_array).reshape(-1, SF)\n",
    "    powers = 2 ** np.arange(SF)[::-1]\n",
    "    symbols = bit_array.dot(powers)\n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962eec88",
   "metadata": {},
   "source": [
    "<text>La funcion symbols to bits: Invierte el proceso anterior: toma una lista de símbolos y los convierte en sus \n",
    "correspondientes representaciones binarias de SF bits. Esto emula la decodificación, recuperando el vector 𝑤(𝑛𝑇𝑠) desde el número 𝑠(𝑛𝑇𝑠)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4d0721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbols_to_bits(symbols, SF):\n",
    "    \"\"\"Convierte los símbolos de vuelta a su representación binaria.\"\"\"\n",
    "    bits = ((symbols[:, None] & (1 << np.arange(SF)[::-1])) > 0).astype(int)\n",
    "    return bits.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2cc5e",
   "metadata": {},
   "source": [
    "<text>  La funcion simulate_encoder_decoder: Es el núcleo de la simulación. \n",
    "\n",
    "1~ Genera bits aleatorios con una distribución uniforme entre 0 y 1 usando np.random.randint.\n",
    "\n",
    "2~ Codifica: convierte esos bits en símbolos utilizando bits_to_symbols.\n",
    "\n",
    "3~ Simula la transmisión: en este primer modelo, la transmisión es perfecta. Es decir, los símbolos recibidos son iguales a los transmitidos (sin errores de canal, por ahora).\n",
    "\n",
    "4~ Decodifica: recupera los bits originales desde los símbolos usando symbols_to_bits.\n",
    "\n",
    "5~ Calcula el BER: compara los bits transmitidos vs. los recibidos para calcular la tasa de error de bit (Bit Error Rate).\n",
    "\n",
    "6~ Imprime resultados: muestra los primeros 64 bits transmitidos y decodificados, junto con el BER final y estadísticas generales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb738c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_encoder_decoder(SF, total_bits):\n",
    "    \"\"\"Genera bits aleatorios, codifica, decodifica y calcula el BER.\"\"\"\n",
    "    assert total_bits % SF == 0, \"El número total de bits debe ser múltiplo de SF\"\n",
    "\n",
    "    # Generar bits aleatorios con distribución uniforme\n",
    "    tx_bits = np.random.randint(0, 2, total_bits)\n",
    "\n",
    "    # Codificación\n",
    "    tx_symbols = bits_to_symbols(tx_bits, SF)\n",
    "\n",
    "    # Transmisión simulada perfecta (sin ruido)\n",
    "    rx_symbols = tx_symbols.copy()  # En canal real, se podría agregar ruido o errores\n",
    "\n",
    "    # Decodificación\n",
    "    rx_bits = symbols_to_bits(rx_symbols, SF)\n",
    "\n",
    "    # Cálculo de BER\n",
    "    bit_errors = np.sum(tx_bits != rx_bits)\n",
    "    ber = bit_errors / total_bits\n",
    "\n",
    "    # Resultados\n",
    "    print(\"Bits transmitidos (primeros 64):  \", tx_bits[:64])\n",
    "    print(\"Bits decodificados (primeros 64):\", rx_bits[:64])\n",
    "    print(f\"\\nTotal de bits transmitidos: {total_bits}\")\n",
    "    print(f\"Errores totales: {bit_errors}\")\n",
    "    print(f\"BER (Bit Error Rate): {ber:.6f}\")\n",
    "\n",
    "# Parámetros de simulación\n",
    "SF = 7  # Spreading Factor\n",
    "num_bits = SF * 1000  # Enviar 1000 símbolos\n",
    "\n",
    "simulate_encoder_decoder(SF, num_bits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
